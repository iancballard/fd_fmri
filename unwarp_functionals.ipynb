{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#os and i/o\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from os.path import abspath\n",
    "import csv\n",
    "\n",
    "#scientific computing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats, optimize\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import scipy.stats\n",
    "\n",
    "#ipython add-ons\n",
    "from IPython.parallel import Client\n",
    "from IPython.display import Image\n",
    "import multiprocessing\n",
    "\n",
    "##nipype\n",
    "import nibabel as nib\n",
    "from nipype.pipeline.engine import Node, MapNode, Workflow\n",
    "from nipype.interfaces.io import DataGrabber, DataFinder, DataSink\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces.fsl import BET\n",
    "from nipype.interfaces.freesurfer.preprocess import ReconAll\n",
    "from nipype.interfaces.freesurfer.utils import MakeAverageSubject\n",
    "from nipype.interfaces.fsl import ExtractROI\n",
    "from nipype.interfaces.fsl import Merge\n",
    "from nipype.interfaces.fsl import TOPUP\n",
    "from nipype.interfaces.fsl import ApplyTOPUP\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preliminary housekeeping\n",
    "home_dir = '/data/home/iballard/fd/'\n",
    "subj_file = home_dir + 'scripts/sub_cb_mappings.txt'\n",
    "acq_params = home_dir + 'scripts/acqparams.txt'\n",
    "os.chdir(home_dir)\n",
    "\n",
    "num_slices = 57 #if you don't know, use nib.load and shape attribute\n",
    "#get subject list\n",
    "sub_list = []\n",
    "with open(subj_file) as f:\n",
    "    for line in f:\n",
    "        (key,val) = line.strip().split(' ') \n",
    "        sub_list.append('fd_' + key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_slice(sub):\n",
    "    import os\n",
    "    import glob\n",
    "    from nipype.interfaces.fsl import ExtractROI\n",
    "    scans = glob.glob('data/' + sub + '/cal/*') #calibration scans\n",
    "    scans.extend(glob.glob('data/' + sub + '/func/*/*.nii.gz')) #functional scans\n",
    "    scans = [s for s in scans if len(s.split('/')[-1].split('_'))==2] #just scans that havent been run\n",
    "    for scan in scans:\n",
    "        old_file = abspath(scan)\n",
    "        new_file = abspath(scan[:-7] + '_' + str(num_slices + 1)) + '.nii.gz'\n",
    "        if not os.path.exists(new_file): #only run if target doesnt exist. \n",
    "            fslroi = ExtractROI(in_file=old_file, roi_file=new_file,\n",
    "                                x_min=0,x_size=-1,y_min=0,y_size=-1,\n",
    "                                z_min=0,z_size= (num_slices + 1))\n",
    "            fslroi.run()\n",
    "    return os.getpid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6824,\n",
       " 6826,\n",
       " 6828,\n",
       " 6830,\n",
       " 6832,\n",
       " 6833,\n",
       " 6836,\n",
       " 6830,\n",
       " 6830,\n",
       " 6826,\n",
       " 6830,\n",
       " 6832,\n",
       " 6830,\n",
       " 6824,\n",
       " 6833,\n",
       " 6826,\n",
       " 6832,\n",
       " 6824,\n",
       " 6830,\n",
       " 6828,\n",
       " 6826,\n",
       " 6838,\n",
       " 6832,\n",
       " 6826]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##add a z slice to all scans\n",
    "pool = multiprocessing.Pool(processes = 8)\n",
    "pool.map(add_slice,sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##take a timepoint of the gradient reversal scans\n",
    "def slice_scans(sub):\n",
    "    identifier = str(num_slices + 1) #file identifier\n",
    "    scans = glob.glob('data/' + sub + '/cal/*' + identifier + '.nii.gz') #padded calibration scans\n",
    "    for scan in scans:\n",
    "        old_file = abspath(scan)\n",
    "        new_file = abspath(scan[:-7] + '_slice.nii.gz')\n",
    "        if not os.path.exists(new_file):\n",
    "            fslroi = ExtractROI(in_file=old_file, roi_file=new_file,\n",
    "                                t_min=1,t_size=1)\n",
    "            fslroi.run()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "pool.map(slice_scans,sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##merge the calibration scans\n",
    "def merge_scans(sub):\n",
    "    identifier = 'slice' #file identifier\n",
    "    cal1 = glob.glob('data/' + sub + '/cal/cal1*' + identifier + '*') #padded calibration scans\n",
    "    cal2 = glob.glob('data/' + sub + '/cal/cal2*' + identifier + '*') #padded calibration scans\n",
    "\n",
    "    if sub == 'fd_115': #extra set of scans for this subject (see notes)\n",
    "        num_scans = 5\n",
    "    else:\n",
    "        num_scans = 4\n",
    "    for i in range(1,num_scans+1):\n",
    "        pe1 = [s for s in cal1 if int(s.split('/')[-1].split('_')[1]) == i][0]\n",
    "        pe0 = [s for s in cal2 if int(s.split('/')[-1].split('_')[1]) == i][0]\n",
    "        out = abspath('data/' + sub + '/cal/b0_both_' + str(i) + '.nii.gz')\n",
    "        if not os.path.exists(out):\n",
    "            merger = Merge(in_files=[pe0,pe1], merged_file=out,dimension = 't')\n",
    "            merger.run()    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "pool.map(merge_scans,sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#execute topup\n",
    "def topup_scans(sub):\n",
    "    scans = glob.glob('data/' + sub + '/cal/b0*.nii.gz') #padded calibration scans\n",
    "    scans = [s for s in scans if len(s.split('/')[-1].split('_'))==3] #just take raw images\n",
    "\n",
    "    for scan in scans:\n",
    "        new_file = abspath(scan[:-7] + '_topup') \n",
    "        unwarped = abspath(scan[:-7] + '_uw') \n",
    "        log = abspath(scan[:-7] + '_log') \n",
    "        field = abspath(scan[:-7] + '_field')\n",
    "        if not os.path.exists(field +'.nii.gz'): #only run if not already run\n",
    "            topup = TOPUP(in_file=scan, encoding_file = acq_params, out_base = new_file,\n",
    "                         out_corrected = unwarped, out_logfile = log,out_field = field)\n",
    "        topup.run()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = multiprocessing.Pool()\n",
    "pool.map(topup_scans,sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##apply topup to functional runs. This has some experiment specific organizing\n",
    "##because I acquire enough data for 4 fieldmaps throughout the experiment\n",
    "def apply_topup(sub):\n",
    "    #padded functional scans\n",
    "    scans = glob.glob('data/' + sub + '/func/*/*' + str(num_slices + 1) + '.nii.gz') \n",
    "    \n",
    "    for scan in scans:\n",
    "        out = scan[:-10] + '_fc.nii.gz' #output file name\n",
    "        if not os.path.exists(out): #only run if it hasn't been run already\n",
    "            #get exp id (sim, loc, func) and run #\n",
    "            exp = scan.split('/')[3] \n",
    "            run = int(scan.split('/')[4].split('_')[1])\n",
    "\n",
    "            if exp == 'loc': #localizers were run last\n",
    "                cal_scan = 4\n",
    "            elif run == 1:\n",
    "                cal_scan = 1\n",
    "            elif run == 2:\n",
    "                cal_scan = 2\n",
    "            elif run == 3:\n",
    "                cal_scan = 3\n",
    "\n",
    "            #one subject has extra cal scan for 2nd localizer run on a different day\n",
    "            if sub == 'fd_115' and exp == 'loc' and run == 2:\n",
    "                cal_scan = 5\n",
    "\n",
    "            #get correct field inputs\n",
    "            base_file = abspath('data/' + sub + '/cal/b0_both_' + str(cal_scan))\n",
    "            movpar = base_file + '_topup_movpar.txt'\n",
    "            fieldcoef = base_file + '_topup_fieldcoef.nii.gz'\n",
    "\n",
    "            applytopup = ApplyTOPUP(in_files = scan, encoding_file = acq_params,\n",
    "                                    out_corrected = out, in_index = [1], method = 'jac',\n",
    "                                    in_topup_movpar = movpar, in_topup_fieldcoef = fieldcoef)  \n",
    "            applytopup.run()\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n",
      "/usr/lib/python2.7/dist-packages/nipype/interfaces/base.py:397: UserWarning: Input in_topup_movpar requires inputs: in_topup_fieldcoef\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool = multiprocessing.Pool(processes = 8)\n",
    "pool.map(apply_topup,sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Basic double checking based on files size. Mostly will check for processes prememptively\n",
    "#killed due to memory overload\n",
    "for sub in sub_list:\n",
    "    scans = glob.glob('data/' + sub + '/func/*/*fc*')\n",
    "    b0 = glob.glob('data/' + sub + '/cal/*field.nii.gz')\n",
    "    if len(scans) != 8:\n",
    "        print sub\n",
    "    \n",
    "    #check b0 for file size\n",
    "    for b in b0:\n",
    "        file_size = np.round(os.path.getsize(b)/1000.0)\n",
    "        if file_size < 4000: #less than 4 MB\n",
    "            print b\n",
    "    \n",
    "    #check field corrected functionals for file size\n",
    "    for scan in scans:\n",
    "        file_size = np.round(os.path.getsize(scan)/1000000.0)\n",
    "        orig_file = scan[:-10] + '.nii.gz' \n",
    "        orig_size = np.round(os.path.getsize(orig_file)/1000000.0)\n",
    "        if file_size < 400: #scan less than 400 MB\n",
    "            print scan\n",
    "        \n",
    "        if abs(file_size - orig_size) > 100: #big difference between file sizes\n",
    "            print abs(file_size - orig_size)\n",
    "            print scan            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/fd_101/func/sim/run_2_58.nii.gz\n",
      "490.5\n",
      "data/fd_101/func/sim/run_1_58.nii.gz\n",
      "603.0\n",
      "data/fd_101/func/ser/run_2_58.nii.gz\n",
      "603.0\n"
     ]
    }
   ],
   "source": [
    "##Specific to this experiment. Sanity check that ser/sim assignment has been done correctly by\n",
    "##examining number of timepoints\n",
    "for sub in sub_list:\n",
    "    loc = glob.glob('data/' + sub + '/func/loc/*58*')\n",
    "    sim = glob.glob('data/' + sub + '/func/sim/*58*')\n",
    "    ser = glob.glob('data/' + sub + '/func/ser/*58*')\n",
    "    \n",
    "    for scan in loc:\n",
    "        img = nib.load(scan)\n",
    "        time = img.shape[3]*1.5\n",
    "        if time < 300 or time > 400: #should be around 5.5 minutes\n",
    "            print scan\n",
    "            print time\n",
    "    for scan in sim:\n",
    "        img = nib.load(scan)\n",
    "        time = img.shape[3]*1.5\n",
    "        if time < 360 or time > 480: #should be around 7 minutes\n",
    "            print scan\n",
    "            print time\n",
    "    for scan in ser:\n",
    "        img = nib.load(scan)\n",
    "        time = img.shape[3]*1.5\n",
    "        if time < 450 or time > 600: #should be around 8.5 minutes\n",
    "            print scan\n",
    "            print time\n",
    "            \n",
    "#Note to self: First subject had longer scans because I was worried about stopping the scanner early\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
