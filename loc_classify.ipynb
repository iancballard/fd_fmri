{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy.stats\n",
    "from ipyparallel import Client\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm \n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import manifold\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing, metrics, feature_selection\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneGroupOut\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rc = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#preliminary housekeeping\n",
    "home_dir = '/data/home/iballard/fd/'\n",
    "subj_file = home_dir + 'subjects.txt'\n",
    "subs = list(np.loadtxt(subj_file,'string'))\n",
    "os.chdir(home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_inv_shrunk_covariance(x,mask):\n",
    "    #see http://www.diedrichsenlab.org/pubs/Walther_Neuroimage_2016.pdf\n",
    "    t,n = x.shape #t measurements by n voxels\n",
    "\n",
    "    #demean\n",
    "    x = x - x.mean(0)\n",
    "\n",
    "    #compute covariance\n",
    "    sample = (1.0/t) * np.dot(np.transpose(x),x)\n",
    "\n",
    "    #copute prior\n",
    "    prior = np.diag(np.diag(sample))\n",
    "\n",
    "    #compute shrinkage\n",
    "    d = 1.0/n * np.linalg.norm(sample - prior,ord = 'fro')**2\n",
    "    y = np.square(x)\n",
    "    r2 = 1.0/n/t**2 * np.sum(np.sum(np.dot(np.transpose(y),y)))- \\\n",
    "    1.0/n/t*np.sum(np.sum(np.square(sample)))\n",
    "\n",
    "    #compute the estimator\n",
    "    shrinkage = max(0,min(1,r2/d))\n",
    "    sigma = shrinkage*prior + (1-shrinkage)*sample\n",
    "\n",
    "    #compute the inverse\n",
    "    try:\n",
    "        inv_sigma = np.linalg.inv(sigma)\n",
    "    except numpy.linalg.linalg.LinAlgError as err:\n",
    "        if 'Singular matrix' in err.message:\n",
    "            inv_sigma = np.linalg.inv(prior) #univariate\n",
    "        else:\n",
    "            raise\n",
    "    \n",
    "    return inv_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#project a onto be\n",
    "def vector_reject(a,b): #a gives variance to be\n",
    "    return a - (np.dot(a,b)/np.dot(b,b)) * b    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make sure MTL masks are exclusive\n",
    "def trim_mask(sub,mask,m):\n",
    "    exclusions = overlap_masks[:]\n",
    "    exclusions.remove(m)\n",
    "\n",
    "    m1 = op.join(home_dir,'data', sub,  'masks', exclusions[0] +'.nii.gz')\n",
    "    m1 = nib.load(m1).get_data().astype(bool)\n",
    "\n",
    "    m2 = op.join(home_dir,'data', sub,  'masks', exclusions[1] +'.nii.gz')\n",
    "    m2 = nib.load(m2).get_data().astype(bool)\n",
    "\n",
    "    bad = np.logical_or(m1,m1)\n",
    "    good = np.invert(bad)\n",
    "\n",
    "    mask = np.logical_and(mask,good)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_inverse_sigma(sub,exp,smooth,masks):\n",
    "    sub_path = op.join(home_dir,'analysis', exp, sub, 'reg','epi', smooth)\n",
    "    for run in map(str,range(1,3)):\n",
    "        res = op.join(sub_path, 'run_'  + run,'res4d_xfm.nii.gz')\n",
    "\n",
    "        if op.exists(res):\n",
    "            res = nib.load(res).get_data().astype(float)\n",
    "\n",
    "            for m in masks:\n",
    "                out_f = op.join(home_dir,'covariance','_'.join([exp,sub,smooth,run,m]) + '.txt')\n",
    "                \n",
    "                if not op.exists(out_f): #don't recompute\n",
    "                    mask = op.join(home_dir,'data', sub,  'masks', m + '.nii.gz')\n",
    "                    mask = nib.load(mask).get_data().astype(bool)\n",
    "                    if m in overlap_masks:\n",
    "                        mask = trim_mask(sub,mask,m)\n",
    "\n",
    "                    x = res[mask]\n",
    "                    x = np.transpose(x)\n",
    "\n",
    "                    inv_sigma = compute_inv_shrunk_covariance(x,m)\n",
    "\n",
    "                    inv_sigma = scipy.linalg.fractional_matrix_power(inv_sigma,.5) #take square root\n",
    "\n",
    "                    np.savetxt(out_f,inv_sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_inverse_sigma(sub,exp,smooth,masks):\n",
    "    for run in map(str,range(1,3)):\n",
    "        for m in masks:\n",
    "            out_f = op.join(home_dir,'covariance','_'.join([exp,sub,run,m]) + '.txt')\n",
    "            if op.exists(out_f):\n",
    "                os.remove(out_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_condition(i):\n",
    "    if i ==1:\n",
    "        cond = 'popout'\n",
    "        trial = 1\n",
    "    elif i < 12:\n",
    "        cond = 'body'\n",
    "        trial = i - 1\n",
    "    elif i < 22:\n",
    "        cond = 'character'\n",
    "        trial = i - 11\n",
    "    elif i < 32:\n",
    "        cond = 'face'\n",
    "        trial = i - 21\n",
    "    elif i < 42:\n",
    "        cond = 'place'\n",
    "        trial = i - 31\n",
    "    elif i < 52:\n",
    "        cond = 'object'\n",
    "        trial = i - 41 \n",
    "    return cond,trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_betas(sub,exp,smooth,masks):\n",
    "\n",
    "    nbetas = 50\n",
    "    exp_id = 'loc-betas'\n",
    "            \n",
    "    all_betas = []\n",
    "    for m in masks:\n",
    "        out_f = op.join(home_dir,'betas', '_'.join([exp_id,sub,smooth,m]) + '.csv')\n",
    "        \n",
    "        #extract saved betas\n",
    "        if not op.exists(out_f):\n",
    "            betas = {'sub':[],'mask':[],'run':[],'condition':[],'value':[],'trial':[],'voxel':[],'row':[]}\n",
    "            sub_path = op.join(home_dir,'analysis', exp_id, sub, 'reg','epi', smooth )\n",
    "\n",
    "            mask = op.join(home_dir,'data', sub,  'masks', m + '.nii.gz')\n",
    "            mask = nib.load(mask).get_data().astype(bool)\n",
    "            if m in overlap_masks:\n",
    "                mask = trim_mask(sub,mask,m)\n",
    "\n",
    "\n",
    "            for run in map(str,range(1,3)):\n",
    "                run_dir = op.join(sub_path, 'run_'  + run)\n",
    "\n",
    "                if os.path.exists(run_dir):\n",
    "\n",
    "                    for i in range(2,nbetas + 2):\n",
    "                        f = run_dir + '/cope' + str(i) + '_xfm.nii.gz'\n",
    "\n",
    "                        cond, trial = get_condition(i)\n",
    "\n",
    "                        #load stat image\n",
    "                        stat = nib.load(f).get_data().astype(float)\n",
    "                        stat = stat[mask]\n",
    "\n",
    "                        for n,val in enumerate(stat):\n",
    "                            betas['voxel'].append(n)                        \n",
    "                            betas['sub'].append(sub)\n",
    "                            betas['value'].append(val)\n",
    "                            betas['mask'].append(m)\n",
    "                            betas['run'].append(int(run))\n",
    "                            betas['condition'].append(cond)\n",
    "                            betas['trial'].append(trial)\n",
    "                            betas['row'].append(i - 1)\n",
    "                else:\n",
    "                    print run_dir\n",
    "\n",
    "            betas = pd.DataFrame(betas)\n",
    "            betas.to_csv(out_f,index = False)\n",
    "            \n",
    "        else: #load from disk\n",
    "            betas = pd.read_csv(out_f)\n",
    "            \n",
    "        all_betas.append(betas)\n",
    "    all_betas = pd.concat(all_betas)\n",
    "    all_betas = all_betas.set_index(['sub', 'run','mask','condition','trial'])\n",
    "    return all_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prewhiten_betas(old_betas,sub,exp,smooth,masks):\n",
    "    \n",
    "    all_betas = []\n",
    "\n",
    "    exp_id = 'loc-betas'\n",
    "        \n",
    "    for m in masks:\n",
    "        out_f = op.join(home_dir,'betas', 'whitened','_'.join([exp_id,sub,smooth,m]) + '.csv')\n",
    "        \n",
    "        if op.exists(out_f):\n",
    "            all_betas.append(pd.read_csv(out_f))\n",
    "            \n",
    "        else:\n",
    "            betas = old_betas.xs(m, level='mask', axis=0)\n",
    "            \n",
    "            for run in map(str,range(1,3)):\n",
    "                #load covariance\n",
    "                inv_sigma = op.join(home_dir,'covariance','_'.join([exp,sub,smooth,run,m]) + '.txt')\n",
    "                if op.exists(inv_sigma):\n",
    "                    inv_sigma = np.loadtxt(inv_sigma)\n",
    "\n",
    "                    for cond in conds:\n",
    "                        for trial in range(1,11):\n",
    "                            vals = betas.loc[(sub,int(run),cond,trial),'value'].values\n",
    "                            whiten_vals = np.dot(inv_sigma,vals)\n",
    "                            betas.loc[(sub,int(run),cond,trial),'value'] = whiten_vals\n",
    "                else:\n",
    "                    print 'no covariance file',inv_sigma\n",
    "                    \n",
    "            out_betas = pd.DataFrame(betas.to_records()) \n",
    "            out_betas['mask'] = m\n",
    "            out_betas.to_csv(out_f,index = False)\n",
    "            all_betas.append(out_betas)\n",
    "        \n",
    "    all_betas = pd.concat(all_betas)\n",
    "    all_betas = all_betas.set_index(['sub', 'run','mask','condition','trial'])\n",
    "    return all_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_sub(sub):\n",
    "\n",
    "    compute_inverse_sigma(sub,exp,smooth,masks)\n",
    "    betas = extract_betas(sub,exp,smooth,masks)\n",
    "    betas = prewhiten_betas(betas,sub,exp,smooth,masks)\n",
    "#         delete_inverse_sigma(sub,exp,smooth,masks) #save disk space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "overlap_masks = ['peri_sim','para_sim','hipp']\n",
    "masks = ['hipp','peri_sim','para_sim']\n",
    "exp = 'loc-betas'\n",
    "smooth = 'smoothed'\n",
    "conds = ['body','character','face','object','place']\n",
    "nconds = len(conds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dview = rc[0:16]\n",
    "dview.block = True\n",
    "\n",
    "dview.push(dict(home_dir=home_dir,\n",
    "                masks = masks,\n",
    "                exp = exp,\n",
    "                conds = conds,\n",
    "                smooth = smooth,\n",
    "                get_condition = get_condition,\n",
    "                overlap_masks = overlap_masks,\n",
    "                prewhiten_betas = prewhiten_betas,\n",
    "                compute_inv_shrunk_covariance = compute_inv_shrunk_covariance,\n",
    "                compute_inverse_sigma = compute_inverse_sigma,\n",
    "                extract_betas = extract_betas,\n",
    "                delete_inverse_sigma = delete_inverse_sigma,\n",
    "                trim_mask = trim_mask\n",
    "                ))\n",
    "dview.execute(\"import numpy as np\")\n",
    "dview.execute(\"import os.path as op\")\n",
    "dview.execute(\"import nibabel as nib\")\n",
    "dview.execute(\"import pandas as pd\")\n",
    "with dview.sync_imports():\n",
    "    import os\n",
    "    import numpy\n",
    "    import scipy\n",
    "    import scipy.stats\n",
    "    import pickle\n",
    "dview.map_sync(run_sub,subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Now classify the visual categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_features(exp,sub,smooth,m):\n",
    "\n",
    "    out_f = op.join(home_dir,'betas','whitened', '_'.join([exp,sub,smooth,m]) + '.csv')\n",
    "    betas = pd.read_csv(out_f)\n",
    "\n",
    "    #drop categories we don't care about\n",
    "    drop_conds = ['character','object']\n",
    "    for c in drop_conds:\n",
    "        betas = betas[betas['condition'] != c]\n",
    "        \n",
    "    return betas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond_map = {'body':0, 'place':1, 'object':3, 'character':4, 'face':2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_data(betas):\n",
    "    runs = []\n",
    "    X = []\n",
    "    y = []\n",
    "    for run in range(1,3):\n",
    "        run_betas = betas[betas['run'] == run]\n",
    "\n",
    "        X_run = run_betas.pivot(index = 'row',columns = 'voxel',values = 'value').values\n",
    "        y_run = run_betas.pivot(index = 'row',columns = 'voxel',values = 'condition')[0].values\n",
    "        y_run = [cond_map[x] for x in y_run]\n",
    "        run = [run]*len(y_run)\n",
    "\n",
    "        #scale \n",
    "        X_run = preprocessing.scale(X_run)\n",
    "\n",
    "        runs.append(run)\n",
    "        y.append(y_run)\n",
    "        X.append(X_run)\n",
    "\n",
    "    X = np.concatenate(X)\n",
    "    y = np.concatenate(y)\n",
    "    runs = np.concatenate(runs)\n",
    "    \n",
    "    return X,y,runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(X,y,runs):\n",
    "    logistic = LogisticRegression(C=1,  \n",
    "                             multi_class = 'multinomial',\n",
    "                            solver = 'lbfgs')\n",
    "    transform = feature_selection.SelectKBest(feature_selection.f_classif,\n",
    "                                                   k = 1000)\n",
    "\n",
    "    clf = make_pipeline(transform, preprocessing.StandardScaler(), logistic  )\n",
    "\n",
    "    #get cross-validated score\n",
    "    cv = LeaveOneGroupOut().split(X, y, runs)\n",
    "    scores = cross_val_score(clf, X,y,cv = cv,\n",
    "                             groups=runs, scoring='accuracy')\n",
    "    \n",
    "    return np.mean(scores),clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_results = {'mask':[],'sub':[],'accuracy':[]}\n",
    "for m in masks:\n",
    "    for sub in subs:\n",
    "        #\n",
    "        betas = load_features(exp,sub,smooth,m)\n",
    "        X,y,runs = prepare_data(betas)\n",
    "        score, clf = classify(X,y,runs)\n",
    "\n",
    "        #fit model to both runs\n",
    "        clf = clf.fit(X,y)\n",
    "\n",
    "        #save to disk\n",
    "        out_f = op.join(home_dir,'classifiers', '_'.join([sub,exp,smooth,m]) + '_logistic.pkl')\n",
    "        output = open(out_f, 'wb')\n",
    "        pickle.dump(clf, output)\n",
    "        output.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fd_104',\n",
       " 'fd_105',\n",
       " 'fd_107',\n",
       " 'fd_108',\n",
       " 'fd_109',\n",
       " 'fd_110',\n",
       " 'fd_112',\n",
       " 'fd_113',\n",
       " 'fd_114',\n",
       " 'fd_115',\n",
       " 'fd_117',\n",
       " 'fd_118',\n",
       " 'fd_119',\n",
       " 'fd_122',\n",
       " 'fd_123',\n",
       " 'fd_124',\n",
       " 'fd_126',\n",
       " 'fd_127',\n",
       " 'fd_128',\n",
       " 'fd_129',\n",
       " 'fd_130',\n",
       " 'fd_132',\n",
       " 'fd_133',\n",
       " 'fd_135',\n",
       " 'fd_136',\n",
       " 'fd_137',\n",
       " 'fd_138',\n",
       " 'fd_140',\n",
       " 'fd_141',\n",
       " 'fd_144',\n",
       " 'fd_147',\n",
       " 'fd_148']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
