{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moss.mosaic import Mosaic\n",
    "import nibabel as nib\n",
    "import multiprocessing\n",
    "#os and i/o\n",
    "import os\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preliminary housekeeping\n",
    "home_dir = '/data/home/iballard/fd/'\n",
    "subj_file = home_dir + 'subjects.txt'\n",
    "subs = list(np.loadtxt(subj_file,'string'))\n",
    "os.chdir(home_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "exp = 'sim_4mm-betas'\n",
    "masks = ['entorhinal']\n",
    "smooth = 'smoothed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_condition(i):\n",
    "    if i < 11:\n",
    "        cond = 'b_plus'\n",
    "        trial = i\n",
    "    elif i < 21:\n",
    "        cond = 'c_plus'\n",
    "        trial = i - 10\n",
    "    elif i < 31:\n",
    "        cond = 'c_minus'\n",
    "        trial = i - 20\n",
    "    elif i < 41:\n",
    "        cond = 'b_minus'\n",
    "        trial = i - 30\n",
    "    return cond,trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_110/reg/epi/smoothed/run_1\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_110/reg/epi/smoothed/run_2\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_110/reg/epi/smoothed/run_3\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_114/reg/epi/smoothed/run_1\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_114/reg/epi/smoothed/run_2\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_114/reg/epi/smoothed/run_3\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_127/reg/epi/smoothed/run_3\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_133/reg/epi/smoothed/run_3\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_138/reg/epi/smoothed/run_1\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_138/reg/epi/smoothed/run_2\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_138/reg/epi/smoothed/run_3\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_147/reg/epi/smoothed/run_1\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_147/reg/epi/smoothed/run_2\n",
      "/data/home/iballard/fd/analysis/sim_4mm-betas/fd_147/reg/epi/smoothed/run_3\n"
     ]
    }
   ],
   "source": [
    "#Saves betas to csv so we don't have to constantly rerun this slow code block\n",
    "for m in masks:\n",
    "    betas = {'sub':[],'mask':[],'run':[],'condition':[],'trial':[],'value':[],'voxel':[],'row':[]}\n",
    "    out_f = op.join(home_dir,'betas', '_'.join([exp,smooth,m]) + '.csv')\n",
    "    \n",
    "    for sub in subs:\n",
    "        sub_path = op.join(home_dir,'analysis', exp, sub, 'reg','epi', smooth )\n",
    "\n",
    "        mask = op.join(home_dir,'data', sub,  'masks', m + '.nii.gz')\n",
    "        mask = nib.load(mask).get_data().astype(bool)\n",
    "\n",
    "        for run in map(str,range(1,4)):\n",
    "            run_dir = op.join(sub_path, 'run_'  + run)\n",
    "            \n",
    "            if os.path.exists(run_dir):\n",
    "                \n",
    "                for i in range(1,41):\n",
    "                    f = run_dir + '/cope' + str(i) + '_xfm.nii.gz'\n",
    "                    cond, trial = get_condition(i)\n",
    "\n",
    "                    #load stat image\n",
    "                    stat = nib.load(f).get_data().astype(float)\n",
    "                    stat = stat[mask]\n",
    "                    \n",
    "                    for n,val in enumerate(stat):\n",
    "                        betas['voxel'].append(n)                        \n",
    "                        betas['sub'].append(sub)\n",
    "                        betas['value'].append(val)\n",
    "                        betas['mask'].append(m)\n",
    "                        betas['run'].append(run)\n",
    "                        betas['condition'].append(cond)\n",
    "                        betas['trial'].append(trial)\n",
    "                        betas['row'].append(i)\n",
    "            else:\n",
    "                print run_dir\n",
    "\n",
    "    betas = pd.DataFrame(betas)\n",
    "    betas.to_csv(out_f)\n",
    "    del betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#set ROIs of interest and load from hard disk\n",
    "x_roi = 'peri_sim'\n",
    "y_roi = 'entorhinal'\n",
    "rois = [x_roi,y_roi]\n",
    "betas = []\n",
    "\n",
    "for m in rois:\n",
    "    f = op.join(home_dir,'betas', '_'.join([exp,smooth,m]) + '.csv')\n",
    "    betas.append(pd.read_csv(f))\n",
    "    \n",
    "betas = pd.concat(betas)\n",
    "betas = betas.set_index(['sub', 'mask','run'])\n",
    "\n",
    "#set ROIs of interest and load from hard disk\n",
    "# del betas\n",
    "# x_roi = 'entorhinal'\n",
    "# y_roi = 'entorhinal'\n",
    "\n",
    "# f = op.join(home_dir,'betas', '_'.join([exp,smooth,x_roi]) + '.csv')\n",
    "  \n",
    "# betas = pd.read_csv(f)\n",
    "# betas = betas.set_index(['sub', 'mask','run'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores_df = {'sub':[],'score_test':[],'score_train':[],'y_roi':[]}\n",
    "\n",
    "for sub in subs:\n",
    "    if sub not in ['fd_110','fd_114','fd_138','fd_147']:\n",
    "        scores_train = []\n",
    "        scores_test = []\n",
    "\n",
    "        #deal with unequal number of runs across subjects\n",
    "        runs = list(set(betas.loc[(sub,x_roi)].index))\n",
    "        if len(runs) == 3:\n",
    "            train_runs = [['1','2'],['1','3'],['2','3']]\n",
    "        elif len(runs) == 2:\n",
    "            train_runs = [['1'],['2']]\n",
    "\n",
    "        for train_set in train_runs:\n",
    "            X_train = []\n",
    "            Y_train = []\n",
    "            for run in runs:\n",
    "                #extract relevant data from betas df\n",
    "                X = betas.loc[(sub,x_roi,run)]\n",
    "                X = X.pivot(index = 'row',columns='voxel', values='value').values\n",
    "\n",
    "                Y = betas.loc[(sub,y_roi,run)]\n",
    "                Y = Y.pivot(index = 'row',columns='voxel', values='value').values\n",
    "\n",
    "                if str(run) in train_set:\n",
    "                    X_train.append(np.copy(X))\n",
    "                    Y_train.append(np.copy(Y))\n",
    "                else:\n",
    "                    X_test = np.copy(X)\n",
    "                    Y_test = np.copy(Y)\n",
    "\n",
    "            #format design matrices for input to sklearn\n",
    "            X_train = np.array(X_train)\n",
    "            Y_train = np.array(Y_train)        \n",
    "\n",
    "            X_train = X_train.reshape(-1, X_train.shape[-1])\n",
    "            Y_train = Y_train.reshape(-1, Y_train.shape[-1])\n",
    "\n",
    "            #standardize\n",
    "            X_train = preprocessing.scale(X_train)\n",
    "            Y_train = preprocessing.scale(Y_train)\n",
    "            X_test = preprocessing.scale(X_test)\n",
    "            Y_test = preprocessing.scale(Y_test)\n",
    "\n",
    "            #compute PLS\n",
    "            pls = PLSRegression(n_components=8,max_iter = 2000)\n",
    "            pls.fit(X_train,Y_train)\n",
    "\n",
    "            score_train = pls.score(X_train,Y_train)\n",
    "            scores_train.append(score_train)\n",
    "\n",
    "            score_test = pls.score(X_test,Y_test)\n",
    "            scores_test.append(score_test)\n",
    "    \n",
    "    #save to DF\n",
    "    scores_df['sub'].append(sub)\n",
    "    scores_df['y_roi'].append(y_roi)\n",
    "    scores_df['score_test'].append(np.mean(scores_test))\n",
    "    scores_df['score_train'].append(np.mean(scores_train))\n",
    "    \n",
    "scores_df = pd.DataFrame(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_test     0.068332\n",
      "score_train    0.481656\n",
      "dtype: float64\n",
      "Ttest_1sampResult(statistic=14.079019892472127, pvalue=5.1820522452162286e-15)\n"
     ]
    }
   ],
   "source": [
    "print scores_df.mean()\n",
    "print scipy.stats.ttest_1samp(scores_df['score_test'],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
