{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Run cross-group analyses that lyman doesn't suppport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os and i/o\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from os.path import abspath\n",
    "import csv\n",
    "\n",
    "#scientific computing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats, optimize\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import scipy.stats\n",
    "\n",
    "#ipython add-ons\n",
    "from IPython.parallel import Client\n",
    "from IPython.display import Image\n",
    "import multiprocessing\n",
    "\n",
    "##nipype\n",
    "import nibabel as nib\n",
    "from nipype.pipeline.engine import Node, MapNode, Workflow\n",
    "from nipype.interfaces.io import DataGrabber, DataFinder, DataSink\n",
    "from nipype.interfaces import fsl\n",
    "from nipype.interfaces.fsl import ImageMeants\n",
    "from nipype.interfaces.fsl import ImageStats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preliminary housekeeping\n",
    "home_dir = '/data/home/iballard/fd/'\n",
    "subj_file = home_dir + 'subjects.txt'\n",
    "sub_list = list(np.loadtxt(subj_file,'string'))\n",
    "os.chdir(home_dir)\n",
    "exps = ['sim','ser']\n",
    "runs = map(str,range(1,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group_dir = home_dir + 'analysis/group_ser_sim_4mm_PEmb/'\n",
    "if not os.path.exists(group_dir):\n",
    "    os.mkdir(group_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Make design file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:workflow:['check', 'execution', 'logging']\n",
      "INFO:workflow:Running serially.\n",
      "INFO:workflow:Executing node model in dir: /data/home/iballard/fd/analysis/group_ser_sim_4mm_PEmb/design/model\n",
      "INFO:workflow:Executing node sinker in dir: /data/home/iballard/fd/analysis/group_ser_sim_4mm_PEmb/design/sinker\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<networkx.classes.digraph.DiGraph at 0x7f1e00607b50>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alternatively, make correlation design file\n",
    "# cov = np.loadtxt(home_dir + '/analysis/omegas_powell.txt')\n",
    "cov = np.loadtxt(home_dir + 'vta_mb.txt')\n",
    "# cov = [x for x in cov if x> -5000]\n",
    "print len(cov)\n",
    "##make regressor and contrast inputs according to FSL rules for paired ttest\n",
    "# regressors = dict(cov = list(cov) )\n",
    "regressors = dict(cov = list(cov))\n",
    "contrasts=[['ser-corr','T',['cov'],[1]]]\n",
    "# regressors = dict(mean = list(np.ones(len(cov))))\n",
    "# contrasts=[['ser-corr','T',['mean'],[1]]]\n",
    "\n",
    "##set up WF so I can control where outputs go\n",
    "model = Node(fsl.MultipleRegressDesign(regressors = regressors, contrasts = contrasts),name='model')\n",
    "wf = Workflow(name = 'design',base_dir = group_dir)\n",
    "sink = Node(DataSink(),name = 'sinker',base_directory = group_dir)\n",
    "wf.connect(model,'design_con',sink,'output.@con')\n",
    "wf.connect(model,'design_grp',sink,'output.@grp')\n",
    "wf.connect(model,'design_mat',sink,'output.@mat')\n",
    "wf.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge the 3d files from ffx analysis into concatenated 4d files\n",
    "images = ['cope','varcope','dof','zstat']\n",
    "ims_to_files = {'cope':'cope1.nii.gz', 'varcope':'varcope1.nii.gz',\n",
    "                'dof':'tdof_t1.nii.gz','zstat':'zstat1.nii.gz'}\n",
    "contrast = 'PE_state'\n",
    "for f in images:\n",
    "    out_dir = group_dir + contrast\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    \n",
    "    #add files to merge command\n",
    "    out_f = out_dir + '/' + f + '_merged.nii.gz'\n",
    "    if not os.path.exists(out_f):\n",
    "        cmd_str = ['fslmerge','-t',out_f]\n",
    "\n",
    "        for exp in ['ser','sim']: #order matters now\n",
    "            for sub in sub_list:\n",
    "                sub_f = home_dir + '/analysis/' + exp + '_4mm-PEfb-diff/' + sub + '/ffx/mni/smoothed/' + \\\n",
    "                    contrast + '/' + ims_to_files[f]\n",
    "                cmd_str.append(sub_f)\n",
    "        cmd_str = ' '.join(cmd_str)\n",
    "        os.system(cmd_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge the 3d files from ffx analysis into concatenated 4d files\n",
    "images = ['cope','varcope','dof','zstat']\n",
    "ims_to_files = {'cope':'cope1.nii.gz', 'varcope':'varcope1.nii.gz',\n",
    "                'dof':'tdof_t1.nii.gz','zstat':'zstat1.nii.gz'}\n",
    "contrast = 'A'\n",
    "subjects = list(np.loadtxt(home_dir+ '/subjects.txt',str))\n",
    "# bad_subs = ['fd_104' ,'fd_107', 'fd_108' ,'fd_109' ,'fd_115' ,'fd_122','fd_133' ,'fd_141']\n",
    "bad_subs = []\n",
    "behav_list = [s for s in subjects if s not in bad_subs]\n",
    "in_tuples = [('A_v_all','ser','PEfb-diff'),('PE_mf','ser','PEfb-diff'),\n",
    "             ('PE_mf_state','ser','PEfb-diff'),('PE_mb','ser','PEfb-diff'),\n",
    "            ('PE_mb_state','ser','PEfb-diff'),('PE','ser','PEfb'),\n",
    "            ('state','ser','PEfb'),('PE_state','ser','PEfb')]\n",
    "\n",
    "for f in images:\n",
    "    out_dir = group_dir + contrast\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    \n",
    "    #add files to merge command\n",
    "    for exp in ['ser']: #order matters now\n",
    "        out_f = out_dir + '/' + f + '_' + exp + '_merged.nii.gz'\n",
    "        if not os.path.exists(out_f):\n",
    "            cmd_str = ['fslmerge','-t',out_f]\n",
    "            for sub in behav_list:\n",
    "                sub_f = home_dir + '/analysis/' + exp + '_4mm-PEfb/' + sub + '/ffx/mni/smoothed/' + \\\n",
    "                    contrast + '/' + ims_to_files[f]\n",
    "                cmd_str.append(sub_f)\n",
    "        cmd_str = ' '.join(cmd_str)\n",
    "        os.system(cmd_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Perform FFX analysis for comparing between experiments\n",
    "images = ['cope']\n",
    "ims_to_files = {'cope':'cope1.nii.gz'}\n",
    "subjects = list(np.loadtxt(home_dir+ '/subjects.txt',str))\n",
    "# bad_subs = ['fd_122']\n",
    "# behav_list = [s for s in subjects if s not in bad_subs]\n",
    "\n",
    "contrast = 'PE_mf_state'\n",
    "if not os.path.exists(group_dir + contrast):\n",
    "    os.mkdir(group_dir + contrast)\n",
    "\n",
    "for f in images:\n",
    "    out_dir = group_dir + contrast + '/diff'\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.mkdir(out_dir)\n",
    "    \n",
    "    #add files to merge command\n",
    "    out_f = out_dir + '/' + f + '_' + 'ser-sim' + '_merged.nii.gz'\n",
    "    if not os.path.exists(out_f):\n",
    "        merge_str = ['fslmerge','-t',out_f]\n",
    "        for sub in subjects:\n",
    "\n",
    "            cmd_str = ['fslmaths']\n",
    "            \n",
    "            sub_dir = home_dir + '/analysis/ser_4mm-PEfb-diff/' + sub + '/ffx/mni/smoothed/'\n",
    "            sub_f = sub_dir + contrast + '/' + ims_to_files[f]\n",
    "            cmd_str.append(sub_f)\n",
    "            \n",
    "            cmd_str.append('-sub')\n",
    "           \n",
    "            sub_dir = home_dir + '/analysis/sim_4mm-PEfb-diff/' + sub + '/ffx/mni/smoothed/'\n",
    "            sub_f = sub_dir + contrast + '/' + ims_to_files[f]\n",
    "            cmd_str.append(sub_f)\n",
    "\n",
    "            \n",
    "            out_file = out_dir + '/diff_' + sub + '.nii.gz'\n",
    "            cmd_str.append(out_file)\n",
    "            os.system(' '.join(cmd_str))\n",
    "\n",
    "            merge_str.append(out_file)\n",
    "        merge_str = ' '.join(merge_str)\n",
    "        os.system(merge_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #Normalize mb images by mf images\n",
    "# images = ['cope']\n",
    "# ims_to_files = {'cope':'cope1.nii.gz'}\n",
    "# subjects = list(np.loadtxt(home_dir+ '/subjects.txt',str))\n",
    "# bad_subs = ['fd_104' ,'fd_107', 'fd_108' ,'fd_109' ,'fd_115' ,'fd_133' ,'fd_141']\n",
    "# # bad_subs = ['fd_122']\n",
    "# behav_list = [s for s in subjects if s not in bad_subs]\n",
    "\n",
    "# contrast = 'state'\n",
    "\n",
    "# for f in images:\n",
    "#     out_dir = group_dir + contrast + '/norm'\n",
    "#     if not os.path.exists(out_dir):\n",
    "#         os.mkdir(out_dir)\n",
    "    \n",
    "#     #add files to merge command\n",
    "#     for exp in ['ser']:#,'sim']: #order matters now\n",
    "#         out_f = out_dir + '/' + f + '_' + exp + '_merged.nii.gz'\n",
    "#         if not os.path.exists(out_f):\n",
    "#             merge_str = ['fslmerge','-t',out_f]\n",
    "#             for sub in behav_list:\n",
    "#                 cmd_str = ['fslmaths']\n",
    "#                 sub_dir = home_dir + '/analysis/' + exp + '_4mm-PEfb-diff/' + sub + '/ffx/mni/smoothed/'\n",
    "#                 sub_f = sub_dir + contrast + '/' + ims_to_files[f]\n",
    "#                 cmd_str.append(sub_f)\n",
    "#                 cmd_str.append('-div')\n",
    "#                 sub_f = sub_dir + 'PE_mf' + '/' + ims_to_files[f]     \n",
    "#                 cmd_str.append(sub_f)\n",
    "#                 out_file = out_dir + '/norm_' + sub + '_' + exp + '.nii.gz'\n",
    "#                 cmd_str.append(out_file)\n",
    "#                 os.system(' '.join(cmd_str))\n",
    "\n",
    "#                 merge_str.append(out_file)\n",
    "                \n",
    "#         merge_str = ' '.join(merge_str)\n",
    "#         os.system(merge_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Do fitting with randomise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = 'ser'\n",
    "contrast = 'PE_mf_state'\n",
    "im_dir = group_dir + contrast +'/diff/'\n",
    "stat_file = im_dir + 'cope_ser-sim_merged.nii.gz'\n",
    "mask_file = home_dir + '/analysis/ser_4mm-PEfb-diff/group/mni/' + contrast + '/mask.nii.gz'\n",
    "\n",
    "cmd_str = ['randomise','-i',stat_file,'-o',im_dir,'-m',mask_file,'-T','-1','-n','1000']\n",
    "cmd_str = ' '.join(cmd_str)\n",
    "os.system(cmd_str)\n",
    "# print cmd_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#do fitting with randomise\n",
    "#input image files\n",
    "def randomise(in_tuple):\n",
    "    contrast,exp,altmodel = in_tuple\n",
    "\n",
    "    im_dir = group_dir + contrast + '/'\n",
    "    if not os.path.exists(im_dir):\n",
    "        os.mkdir(im_dir)\n",
    "        \n",
    "#     im_dir = group_dir + 'PE_contrast +'/'\n",
    "#     stat_file = im_dir + 'cope_' + exp + '_merged.nii.gz'\n",
    "#     mask_file = home_dir + '/analysis/ser_4mm-' + altmodel + '/group/mni/' + contrast + '/mask.nii.gz'\n",
    "#     cmd_str = ['randomise','-i',stat_file,'-o',im_dir,'-m', mask_file,'-C','2.3','-1','-n','1000']\n",
    "    \n",
    "    #input design files\n",
    "    stat_file = home_dir + 'analysis/group_ser_sim_4mm/' + contrast + \\\n",
    "        '/cope_' + exp + '_merged.nii.gz'\n",
    "\n",
    "    design_dir = group_dir + '/design/sinker/output/'\n",
    "    t_con_file = design_dir + 'design.con'\n",
    "    cov_split_file = design_dir + 'design.grp'\n",
    "    design_file = design_dir + 'design.mat'\n",
    "    cmd_str = ['randomise','-i',stat_file,'-o',im_dir,'-d',design_file,\n",
    "               '-t',t_con_file,'-m',mask_file,'-n','1000','-D','-C','1.7']\n",
    "    cmd_str = ' '.join(cmd_str)\n",
    "    os.system(cmd_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "in_tuples = [('A_v_all','ser','PEfb-diff'),('PE_mf','ser','PEfb-diff'),\n",
    "             ('PE_mf_state','ser','PEfb-diff'),('PE_mb','ser','PEfb-diff'),\n",
    "            ('PE_mb_state','ser','PEfb-diff'),('PE','ser','PEfb'),\n",
    "            ('state','ser','PEfb'),('PE_state','ser','PEfb'),\n",
    "            ('A','ser','PEfb-diff')]\n",
    "pool = multiprocessing.Pool(processes = len(in_tuples))\n",
    "pool.map(randomise,in_tuples)\n",
    "pool.terminate()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Flameo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make design file for paired t-test\n",
    "num_subs = len(sub_list)\n",
    "group_dir = home_dir + 'analysis/group_ser_sim_4mm/'\n",
    "\n",
    "##make regressor and contrast inputs according to FSL rules for paired ttest\n",
    "regressors = dict(diff = list(np.hstack([np.ones(num_subs)*1.0,np.ones(num_subs)-2.0])))\n",
    "for i in range(num_subs):\n",
    "    col = np.zeros(num_subs*2)\n",
    "    col[i] = 1.0\n",
    "    col[i + num_subs] = 1.0\n",
    "    regressors['sub' + str(i)] = list(col)\n",
    "    \n",
    "# contrasts=[['ser-sim','T',['diff'],[1]], ['sim-ser','T',['diff'],[-1]]]\n",
    "contrasts=[['ser-sim','T',['diff'],[1]]]\n",
    "\n",
    "##set up WF so I can control where outputs go\n",
    "# model = Node(fsl.MultipleRegressDesign(regressors = regressors, contrasts = contrasts),name='model')\n",
    "\n",
    "#for randomise, we need groups for exchangability blocks\n",
    "group = list(np.hstack([np.arange(num_subs)+1,np.arange(num_subs)+1]))\n",
    "model = Node(fsl.MultipleRegressDesign(regressors = regressors, \n",
    "                                       contrasts = contrasts, groups = group),name='model')\n",
    "\n",
    "\n",
    "wf = Workflow(name = 'design',base_dir = group_dir)\n",
    "sink = Node(DataSink(),name = 'sinker',base_directory = group_dir)\n",
    "wf.connect(model,'design_con',sink,'output.@con')\n",
    "wf.connect(model,'design_grp',sink,'output.@grp')\n",
    "wf.connect(model,'design_mat',sink,'output.@mat')\n",
    "wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Run flameo\n",
    "# contrast = 'PE_mb'\n",
    "# wf = Workflow(name = 'flameo',base_dir = group_dir)\n",
    "# exp = 'ser'\n",
    "# #input image files\n",
    "# im_dir = group_dir + contrast\n",
    "# cope_file = im_dir + '/cope_' + exp + '_merged.nii.gz'\n",
    "# var_cope_file = im_dir + '/varcope_' + exp + '_merged.nii.gz'\n",
    "# dof_var_cope_file = im_dir + '/dof_' + exp + '_merged.nii.gz'\n",
    "\n",
    "# #input design files\n",
    "# design_dir = group_dir + '/design/sinker/output/'\n",
    "# t_con_file = design_dir + 'design.con'\n",
    "# cov_split_file = design_dir + 'design.grp'\n",
    "# design_file = design_dir + 'design.mat'\n",
    "\n",
    "# #mask file\n",
    "# mask_file = home_dir + '/analysis/ser_8mm-PEfb-diff/group/mni/' + contrast + '/mask.nii.gz'\n",
    "\n",
    "# #set up flame\n",
    "# flameo = Node(fsl.FLAMEO(cope_file = cope_file, var_cope_file= var_cope_file,\n",
    "#                     dof_var_cope_file = dof_var_cope_file, run_mode = 'flame1',\n",
    "#                    t_con_file = t_con_file, cov_split_file = cov_split_file, \n",
    "#                     design_file = design_file, mask_file = mask_file), name = 'flameo')\n",
    "\n",
    "# #estimate smoothness\n",
    "# smoothest = Node(fsl.SmoothEstimate(mask_file = mask_file),name='smoothest')\n",
    "# wf.connect(flameo,'zstats',smoothest,'zstat_file')\n",
    "\n",
    "# #set up cluster correction\n",
    "# cluster = Node(fsl.Cluster(threshold = 2.3, pthreshold = 0.05, out_threshold_file = True,\n",
    "#                           out_index_file = True, out_localmax_txt_file=True,\n",
    "#                            peak_distance=30, use_mm=True),name='cluster')\n",
    "# wf.connect(smoothest,'dlh',cluster,'dlh')\n",
    "# wf.connect(smoothest,'volume',cluster,'volume')\n",
    "# wf.connect(flameo,'zstats',cluster,'in_file')\n",
    "\n",
    "# ##set up DataSink so I can control where outputs go\n",
    "# sink = Node(DataSink(),name = 'sinker',base_directory = group_dir)\n",
    "# wf.connect(flameo,'copes',sink,'output.copes')\n",
    "# wf.connect(flameo,'fstats',sink,'output.fstats')\n",
    "# wf.connect(flameo,'mrefvars',sink,'output.mrefvars')\n",
    "# wf.connect(flameo,'pes',sink,'output.pes')\n",
    "# wf.connect(flameo,'res4d',sink,'output.res4d')\n",
    "# wf.connect(flameo,'stats_dir',sink,'output.stats_dir')\n",
    "# wf.connect(flameo,'tdof',sink,'output.tdof')\n",
    "# wf.connect(flameo,'tstats',sink,'output.tstats')\n",
    "# wf.connect(flameo,'var_copes',sink,'output.varcopes')\n",
    "# wf.connect(flameo,'weights',sink,'output.weights')\n",
    "# wf.connect(flameo,'zfstats',sink,'output.zfstats')\n",
    "# wf.connect(flameo,'zstats',sink,'output.zstats')\n",
    "\n",
    "# wf.connect(cluster,'index_file',sink,'output.cluster.index_file')\n",
    "# wf.connect(cluster,'localmax_txt_file',sink,'output.cluster.localmax_txt_file')\n",
    "# wf.connect(cluster,'localmax_vol_file',sink,'output.cluster.localmax_vol_file')\n",
    "# wf.connect(cluster,'max_file',sink,'output.cluster.max_file')\n",
    "# wf.connect(cluster,'mean_file',sink,'output.cluster.mean_file')\n",
    "# wf.connect(cluster,'pval_file',sink,'output.cluster.pval_file')\n",
    "# wf.connect(cluster,'size_file',sink,'output.cluster.size_file')\n",
    "# wf.connect(cluster,'threshold_file',sink,'output.cluster.threshold_file')\n",
    "\n",
    "# wf.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# wf.write_graph('workflow_graph.dot')\n",
    "# Image(filename = '/data/home/iballard/fd/analysis/group_ser_sim/flameo/workflow_graph.dot.png' ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
