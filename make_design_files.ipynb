{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#os and i/o\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from os.path import abspath\n",
    "import csv\n",
    "\n",
    "#scientific computing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats, optimize\n",
    "from pandas import DataFrame, Series\n",
    "import seaborn as sns\n",
    "import random as rd\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "import scipy.stats\n",
    "\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes design files for the ser, loc, and sim experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preliminary stuff\n",
    "home_dir = '/data/home/iballard/fd/'\n",
    "subj_file = home_dir + 'scripts/sub_cb_mappings.txt'\n",
    "os.chdir(home_dir)\n",
    "\n",
    "event_dur = 0 #duration for all events\n",
    "\n",
    "#get subject list\n",
    "sub_list = []\n",
    "sub_to_cb = {}\n",
    "with open(subj_file) as f:\n",
    "    for line in f:\n",
    "        (key,val) = line.strip().split(' ') \n",
    "        sub_list.append('fd_' + key)\n",
    "        sub_to_cb['fd_' + key] = int(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOCALIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##get timing file for object localizer\n",
    "def load_timing_file(run,time_to_drop):\n",
    "    loc_file = home_dir + '/loc_timing/script_kidLoc_2Hz_run' + str(run)\n",
    "    trial_type = []\n",
    "    time = []\n",
    "    with open(loc_file) as f:\n",
    "        for n,line in enumerate(f):\n",
    "            l = line.strip('\\n').split('\\t')\n",
    "            if len(l)==5: #ignore file header and footer\n",
    "                trial_type.append(int(l[2]))\n",
    "                time.append(float(l[1]) - time_to_drop)\n",
    "    return trial_type, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#trial type dictionary for object localizer\n",
    "# def trial_type_dict():\n",
    "#     return {0:'scramble', 1:'face-adult', 2:'face-child', 3:'body', 4:'limb', 5:'car',\n",
    "#             6:'guitar', 7:'place', 8:'house', 9:'word', 10:'number'}\n",
    "def trial_type_dict():\n",
    "    return {0:'scramble', 1:'face', 2:'face', 3:'body', 4:'body', 5:'object',\n",
    "            6:'object', 7:'place', 8:'place', 9:'character', 10:'character'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_loc_file(design_dir,cb):\n",
    "    \n",
    "    time_to_drop = -3\n",
    "    trial_dict = trial_type_dict()\n",
    "    duration = 4 #all blocks are 4s\n",
    "    \n",
    "    #set up run counterbalance\n",
    "    if cb==1:\n",
    "        run_dict = {1: '1', 2:'2'}\n",
    "    else:\n",
    "        run_dict = {1: '2', 2:'1'}\n",
    "    \n",
    "    #prepare out file\n",
    "    out_file = design_dir + 'loc.csv'\n",
    "    if os.path.exists(out_file):\n",
    "        os.remove(out_file)\n",
    "    out_f = open(out_file,'w')\n",
    "    out_f.write('run,condition,onset,duration\\n')\n",
    "    for run in range(1,3):\n",
    "        trial_type, time = load_timing_file(run,time_to_drop)\n",
    "\n",
    "        #write out file\n",
    "        for n,trial in enumerate(trial_type):\n",
    "            if n > 0 and trial != trial_type[n-1]: #start of a new trial\n",
    "                if trial_dict[trial] != 'scramble': #not a condition\n",
    "                    new_line = ','.join([run_dict[run],trial_dict[trial],str(time[n]),str(4)+'\\n'])\n",
    "                    out_f.write(new_line)\n",
    "    out_f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write output\n",
    "for sub in sub_list:\n",
    "    design_dir = home_dir + 'data/' + sub + '/design/' #make design folder\n",
    "    if not os.path.exists(design_dir):\n",
    "        os.makedirs(design_dir)\n",
    "    \n",
    "    #write file\n",
    "    write_loc_file(design_dir, sub_to_cb[sub])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genereic code for both the SIM and SER experiments (processing log files, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_log_files(log_files):\n",
    "    full_data = {}\n",
    "    for n,f in enumerate(log_files):\n",
    "        \n",
    "        #read file\n",
    "        subj_file = open(os.path.join(data_dir,f),'r')\n",
    "        subj_file = subj_file.readlines()\n",
    "        subj_file = np.array(subj_file)\n",
    "        \n",
    "        ##process file into dictionary of dictionaries\n",
    "        subj_dict = {}\n",
    "        for n,line in enumerate(subj_file):\n",
    "            subject_line = line.split(' ')[1].split('=')[0].split('%20') #0th index is subid, 1st is that lines id\n",
    "            if len(subject_line) == 2:\n",
    "                try: \n",
    "                    full_data[subject_line[0]][subject_line[1]] = line.split(' ')[1].split('=')[1].strip('\\n')\n",
    "                except:\n",
    "                    full_data[subject_line[0]] = {} ##make dictionary\n",
    "                    full_data[subject_line[0]][subject_line[1]] = line.split(' ')[1].split('=')[1].strip('\\n')\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##make subject lists\n",
    "data_dir = '/home/iballard/Dropbox/fd/'\n",
    "\n",
    "##process data for both sim and ser experiments\n",
    "log_files = glob.glob(data_dir + 'data/scanning/*log')\n",
    "\n",
    "##process log files\n",
    "full_data = process_log_files(log_files)\n",
    "temp_dict = {}\n",
    "for f in full_data:\n",
    "    temp_dict[f] = full_data[f]\n",
    "full_data = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#processes timing files to return times where a condition is rewarded, or not\n",
    "def get_times(all_times,order,rew,cond_code,rew_code):\n",
    "    cond = np.where([order == cond_code])[1]\n",
    "    rewarded = np.where(rew[cond] == rew_code)\n",
    "    indices = cond[rewarded]\n",
    "    times = all_times[indices]\n",
    "    return times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parses the full data file to make data of interest more accesible\n",
    "def load_timing_data(experiment,data):\n",
    "    im_time = np.array(data['im_time_' + experiment].split(',')).astype('float')\n",
    "    fb_time = np.array(data['fb_time_' + experiment].split(',')).astype('float')\n",
    "    iti_time = np.array(data['iti_time_' + experiment].split(',')).astype('float')\n",
    "    cond = np.array( map(float, data['cond_' + experiment].split(',') ))\n",
    "    rew =  np.array( map(float, data['rew_' + experiment].split(',') ))\n",
    "    order = np.array( map(float, data['trial_order_' + experiment].split(',')))\n",
    "    \n",
    "    #add iti times to im_time because cond indexing includes itis\n",
    "    im_time = np.concatenate((iti_time,im_time),axis=0)\n",
    "    im_time = np.sort(im_time)\n",
    "        \n",
    "    return im_time, fb_time, iti_time, cond, rew, order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#given info about run, event time,name, and duration, writes to lyman file\n",
    "def write_entry(entry,time_to_drop,out_f,run,cond_name,event_dur,mvpa,scan_time):\n",
    "    if not mvpa or (entry + 7)<scan_time: #only write if event is within scan time\n",
    "        entry = entry - time_to_drop #adjust for dropped scans\n",
    "        new_line = ','.join([str(run),cond_name,str(entry),str(event_dur)+'\\n'])\n",
    "        out_f.write(new_line)\n",
    "    return out_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_sim_file(sub,event_dur,mvpa):\n",
    "    time_to_drop = 9.0 #number of seconds of scans to drop\n",
    "    design_dir = home_dir + 'data/' + sub + '/design/'\n",
    "\n",
    "    if mvpa:\n",
    "        cond_dict = {1:'pair',2:'single',3:'pair',4:'single'}\n",
    "        out_file = design_dir + 'sim_state.csv'\n",
    "    else:\n",
    "        cond_dict = {1:'AB_plus',2:'B_minus',3:'AC_minus',4:'C_plus'}\n",
    "        out_file = design_dir + 'sim_noswitch.csv'\n",
    "\n",
    "    #prepare out file\n",
    "    if os.path.exists(out_file):\n",
    "        os.remove(out_file)\n",
    "    out_f = open(out_file,'w')\n",
    "    out_f.write('run,condition,onset,duration\\n')\n",
    "\n",
    "    #add timing info for each of the events of interest\n",
    "    for run in range(1,4):\n",
    "        if sub == 'fd_126': #made a mistake in these sub #s. Check notes\n",
    "            f = '125_' + str(run)\n",
    "        elif sub == 'fd_127':\n",
    "            f = '126_' + str(run)\n",
    "        else:\n",
    "            f = sub[-3:] + '_' + str(run) #get subject and run id\n",
    "        \n",
    "        \n",
    "        out_run = run\n",
    "        if sub == 'fd_127' and run == 1:\n",
    "            continue #no run 1\n",
    "        if sub == 'fd_127' and run == 2:\n",
    "            out_run = 1\n",
    "        if sub == 'fd_127' and run == 3:\n",
    "            out_run = 2\n",
    "        if sub == 'fd_133' and run == 2:\n",
    "            continue #no run 2 of sim\n",
    "        if sub == 'fd_133' and run == 3:\n",
    "            out_run = 2\n",
    "        \n",
    "        #get length of run for that subject. For MVPA, want to make sure timing files are\n",
    "        #cropped for runs that have been cropped\n",
    "        crop_run = abspath('data/' + sub + '/func/sim/run_' + str(run) + '_fc_crop.nii.gz')\n",
    "        if os.path.exists(crop_run):\n",
    "            img = nib.load(crop_run)\n",
    "        else:\n",
    "            img = nib.load(abspath('data/' + sub + '/func/sim/run_' + str(run) + '_fc.nii.gz'))\n",
    "\n",
    "        scan_time = img.shape[3]*1.5\n",
    "\n",
    "        #load subject info\n",
    "        im_time, fb_time, iti_time, cond, rew, order = load_timing_data('sim',full_data[f])\n",
    "\n",
    "        #write condition files\n",
    "        for condition in cond_dict.keys(): #loop through conditions\n",
    "            for rew_or_switch in range(0,2): #loop through reward\n",
    "                times = get_times(im_time,order,rew,condition,rew_or_switch)\n",
    "                for entry in times:\n",
    "                    cond_name = cond_dict[condition]\n",
    "#                     if (rew_or_switch == 1 and condition in [2,3]) or \\\n",
    "#                         (rew_or_switch ==0 and condition in [1,4]): #surprise no reward\n",
    "#                             cond_name = cond_name + '_switch'\n",
    "                    out_f = write_entry(entry,time_to_drop,out_f,out_run,cond_name,event_dur,mvpa, scan_time)\n",
    "   \n",
    "        #add entry for feedback times (if not mvpa)\n",
    "        if not mvpa:\n",
    "            for entry in fb_time:\n",
    "                out_f = write_entry(entry,time_to_drop,out_f,out_run,'feedback',event_dur,mvpa,scan_time)\n",
    "                \n",
    "    out_f.close()      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write output\n",
    "for sub in sub_list:\n",
    "    write_sim_file(sub,event_dur,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_ser_file(sub,event_dur,mvpa):\n",
    "    time_to_drop = 9.0 #number of seconds of scans to drop\n",
    "    condition = 'ser'\n",
    "    design_dir = home_dir + 'data/' + sub + '/design/'\n",
    "\n",
    "    if mvpa:\n",
    "        cond_dict = {1:'A',2:'serial',3:'single',4:'A',5:'serial',6:'single'}\n",
    "        out_file = design_dir + condition +'_state.csv'\n",
    "    else:\n",
    "        cond_dict = {1:'A',2:'B_plus',3:'B_minus',4:'A',5:'C_minus',6:'C_plus'}\n",
    "        out_file = design_dir + condition +'_noswitch.csv'\n",
    "\n",
    "    #prepare out file\n",
    "    if os.path.exists(out_file):\n",
    "        os.remove(out_file)\n",
    "    out_f = open(out_file,'w')\n",
    "    out_f.write('run,condition,onset,duration\\n')\n",
    "\n",
    "    #add timing info for each of the events of interest\n",
    "    for run in range(1,4):\n",
    "        if sub == 'fd_126': #made a mistake in these sub #s. Check notes\n",
    "            f = '125_' + str(run)\n",
    "        elif sub == 'fd_127':\n",
    "            f = '126_' + str(run)\n",
    "        else:\n",
    "            f = sub[-3:] + '_' + str(run) #get subject and run id \n",
    "        \n",
    "        #some obnoxious stuff to fix run ordering when there are missing runs\n",
    "        out_run = run\n",
    "        if sub == 'fd_127' and run == 1:\n",
    "            continue #no run 1\n",
    "        if sub == 'fd_127' and run == 2:\n",
    "            out_run = 1\n",
    "        if sub == 'fd_127' and run == 3:\n",
    "            out_run = 2\n",
    "        \n",
    "        #get length of run for that subject. For MVPA, want to make sure timing files are\n",
    "        #cropped for runs that have been cropped\n",
    "        crop_run = abspath('data/' + sub + '/func/ser/run_' + str(run) + '_fc_crop.nii.gz')\n",
    "        if os.path.exists(crop_run):\n",
    "            img = nib.load(crop_run)\n",
    "        else:\n",
    "            img = nib.load(abspath('data/' + sub + '/func/ser/run_' + str(run) + '_fc.nii.gz'))\n",
    "\n",
    "        scan_time = img.shape[3]*1.5\n",
    "        \n",
    "        #load subject info\n",
    "        im_time, fb_time, iti_time, cond, rew, order = load_timing_data('ser',full_data[f])\n",
    "\n",
    "        for condition in cond_dict.keys(): #loop through conditions\n",
    "            if cond_dict[condition] != 'A': #A is never rewarded\n",
    "                for rew_or_switch in range(0,2): #loop through reward\n",
    "                    times = get_times(im_time,order,rew,condition,rew_or_switch)\n",
    "\n",
    "                    for entry in times:\n",
    "                        cond_name = cond_dict[condition]\n",
    "#                         if (rew_or_switch == 1 and condition in [3,5]) or \\\n",
    "#                             (rew_or_switch ==0 and condition in [2,6]): #surprise no reward\n",
    "#                                 cond_name = cond_name + '_switch'\n",
    "                        out_f = write_entry(entry,time_to_drop,out_f,out_run,cond_name,event_dur, mvpa, scan_time)\n",
    "            \n",
    "            else: #A condition\n",
    "                if not mvpa:\n",
    "                    times = get_times(im_time,order,rew,condition,0)\n",
    "                    for entry in times:\n",
    "                        cond_name = cond_dict[condition]\n",
    "                        out_f = write_entry(entry,time_to_drop,out_f,out_run,cond_name,event_dur, mvpa, scan_time)\n",
    "                    \n",
    "        #add entry for feedback times\n",
    "        if not mvpa:\n",
    "            for entry in fb_time:\n",
    "                out_f = write_entry(entry,time_to_drop,out_f,out_run,'feedback',event_dur,mvpa, scan_time)      \n",
    "    out_f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write output\n",
    "for sub in sub_list:\n",
    "    write_ser_file(sub,event_dur,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
